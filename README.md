```markdown
# ðŸ§  Reinforcement Learning Q-Agents

This repository contains classical Q-learning agents implemented from scratch using `gymnasium`. The agents are trained to solve two fundamental RL environments: `FrozenLake-v1` and `Taxi-v3`. The project includes reward tracking, value visualization, live testing with rendering, and analysis of training performance.

## ðŸš€ Highlights
- âœ… Q-learning algorithm with Îµ-greedy exploration
- âœ… Visualizations of agent performance (reward curves, heatmaps)
- âœ… Real-time rendering of the trained agents
- âœ… Class-based modular structure for reuse and testing
- âœ… Support for noisy environments (`is_slippery=True`)

## ðŸ§  Environments
| Environment | Description |
|-------------|-------------|
| `FrozenLake-v1` | Navigate a slippery 4x4 grid without falling into holes |
| `Taxi-v3`       | Pick up and drop off passengers in a 5x5 grid world with a 500-state space |

## ðŸ§ª How to Run

### ðŸš¥ Install dependencies
```bash
pip install -r requirements.txt
```

### ðŸ§Š FrozenLake Agent (Deterministic)
```bash
python frozen_lake.py
```

### ðŸš• Taxi Agent (with rendering)
```bash
python taxi.py
```

## ðŸ“Š Visualizations
- ðŸ“ˆ Reward per episode tracking
- ðŸŸ¨ Heatmaps of state values from the Q-table
- ðŸŽ® Live rendering of the agentâ€™s behavior

## ðŸ’¡ Future Work
- Add SARSA and Dyna-Q variants for comparison  
- Extend to continuous environments using function approximation  
- Log Q-table evolution with TensorBoard or Weights & Biases



---
